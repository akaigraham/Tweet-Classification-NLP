{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Sentiment Classification (Module 4 Project - Kai Graham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Process - CRISP-DM\n",
    "I will be following the Cross-Industry Standard Process for Data Mining (CRISP-DM), with the following iterative steps.\n",
    "1. Business Understanding\n",
    "2. Data Understanding\n",
    "3. Data Preparation\n",
    "4. Modeling\n",
    "5. Evaluation\n",
    "6. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Understanding\n",
    "I will be building a classifier to sort tweets based on sentiment (positive vs. negative vs. neutral).\n",
    "\n",
    "[...] Further information needed about stakeholders, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Understanding\n",
    "The dataset used within this process comes from [...], obtained from [...]\n",
    "\n",
    "This section will focus on importing and exploring the data available to us as we begin to think about modeling and text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "SEED = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to think about validation and train-test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset and begin exploring\n",
    "df = pd.read_csv('judge-1377884607_tweet_product_company.csv', encoding='latin_1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# as we can see above, we have successfully loaded the dataset\n",
    "# further information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             product  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            emotion  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  \n",
       "3  Negative emotion  \n",
       "4  Positive emotion  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename columns so they are easier to work with \n",
    "df.columns = ['text', 'product', 'emotion']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text          1\n",
       "product    5802\n",
       "emotion       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Holler Gram for iPad on the iTunes App Store -...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Attn: All  #SXSW frineds, @mention Register fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Anyone at  #sxsw want to sell their old iPad?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text product  \\\n",
       "5   @teachntech00 New iPad Apps For #SpeechTherapy...     NaN   \n",
       "6                                                 NaN     NaN   \n",
       "16  Holler Gram for iPad on the iTunes App Store -...     NaN   \n",
       "32  Attn: All  #SXSW frineds, @mention Register fo...     NaN   \n",
       "33      Anyone at  #sxsw want to sell their old iPad?     NaN   \n",
       "\n",
       "                               emotion  \n",
       "5   No emotion toward brand or product  \n",
       "6   No emotion toward brand or product  \n",
       "16  No emotion toward brand or product  \n",
       "32  No emotion toward brand or product  \n",
       "33  No emotion toward brand or product  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there appear to be quite a bit of missing product entries - examine further\n",
    "missing_products = df.loc[df['product'].isna()]\n",
    "missing_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No emotion toward brand or product', 'Positive emotion',\n",
       "       'Negative emotion', \"I can't tell\"], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if there are any entries not listed as no emotion toward brand or product\n",
    "missing_products['emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5298\n",
       "Positive emotion                       306\n",
       "I can't tell                           147\n",
       "Negative emotion                        51\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_products['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text product                             emotion\n",
       "6  NaN     NaN  No emotion toward brand or product"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the one missing text entry\n",
    "df.loc[df['text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9092 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   text     9092 non-null   object\n",
      " 1   product  3291 non-null   object\n",
      " 2   emotion  9092 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 284.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# looks like no text, we will drop this entry\n",
    "clean_df = df.dropna(subset=['text'])\n",
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8936 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   text     8936 non-null   object\n",
      " 1   product  3282 non-null   object\n",
      " 2   emotion  8936 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 279.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# remove all I can't tell from the dataset as we don't have proper labels for these\n",
    "clean_df = clean_df.loc[clean_df['emotion'] != \"I can't tell\"]\n",
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8936 entries, 0 to 9092\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   text     8936 non-null   object\n",
      " 1   emotion  8936 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 209.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# for the time being we will ignore the product column as we are only focused on \n",
    "# emotion of the texts - drop the product column \n",
    "clean_df = clean_df.drop(['product'], axis=1)\n",
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           emotion\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  Negative emotion\n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  Positive emotion\n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...  Positive emotion\n",
       "3  @sxsw I hope this year's festival isn't as cra...  Negative emotion\n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  Positive emotion"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text       False\n",
       "emotion    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if any further missing values or duplicates\n",
    "clean_df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicates\n",
    "clean_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates as there are only 22 in our dataset\n",
    "clean_df = clean_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check it worked\n",
    "clean_df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no more duplicates -- good to move on to the next stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8914 entries, 0 to 9092\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   text     8914 non-null   object\n",
      " 1   emotion  8914 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 208.9+ KB\n"
     ]
    }
   ],
   "source": [
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5375\n",
       "Positive emotion                      2970\n",
       "Negative emotion                       569\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have 8914 records remaining, see how may are listed as neutral\n",
    "clean_df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive emotion    2970\n",
       "Negative emotion     569\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like the majority are no emotion toward brand or product, but to begin\n",
    "# we will focus just on building a binary nlp model\n",
    "# drop entries listed as no emotion\n",
    "binary_clean_df = clean_df.loc[clean_df['emotion'] != 'No emotion toward brand or product']\n",
    "binary_clean_df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(binary_clean_df, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into data and target\n",
    "train_data = train_df['text']\n",
    "train_target = train_df['emotion']\n",
    "\n",
    "test_data = test_df['text']\n",
    "test_target = test_df['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, FreqDist\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in stop words from english language\n",
    "stopwords_list = stopwords.words('english') + list(string.punctuation)\n",
    "stopwords_list += [\"''\", '\"\"', '...', '``']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to process a single tweet\n",
    "def process_tweet(tweet):\n",
    "    \"\"\"\n",
    "    Input: tweet of type str\n",
    "    Function tokenizes tweet using function from nltk\n",
    "    Lowercase every token, remove any stopwords found in stopwords_list from the tokenized article, \n",
    "    and return the results\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords_list]\n",
    "    return stopwords_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use map function to call process_tweet on our data\n",
    "processed_data = list(map(process_tweet, train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['google',\n",
       " 'crisis',\n",
       " 'response',\n",
       " 'site',\n",
       " 'w/',\n",
       " 'good',\n",
       " 'info',\n",
       " 'japanese',\n",
       " 'earthquake/tsunami',\n",
       " 'link',\n",
       " 'sxsw',\n",
       " 'sxswi']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7684    #Google Crisis Response has a site up w/ good ...\n",
       "9063    @mention You should get the iPad 2  to save yo...\n",
       "8457    It was either go to #SXSW or wait in line and ...\n",
       "2040    Sweet... Apple listened to us!  A temp Apple S...\n",
       "285     At #SXSW, Apple schools the marketing experts ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like our tokenizing worked properly, as well as the removal of some stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5376"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get total vocabulary size of our training set\n",
    "total_vocab = set()\n",
    "for tweet in processed_data:\n",
    "    total_vocab.update(tweet)\n",
    "len(total_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of unique words in our training set is 5374"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sxsw', 2758),\n",
       " ('mention', 1878),\n",
       " ('link', 989),\n",
       " ('ipad', 891),\n",
       " ('rt', 810),\n",
       " ('apple', 769),\n",
       " ('google', 656),\n",
       " ('iphone', 514),\n",
       " ('quot', 479),\n",
       " ('store', 424),\n",
       " ('2', 418),\n",
       " (\"'s\", 412),\n",
       " ('app', 325),\n",
       " ('new', 295),\n",
       " ('austin', 241),\n",
       " ('android', 174),\n",
       " (\"n't\", 172),\n",
       " ('amp', 169),\n",
       " ('ipad2', 166),\n",
       " ('launch', 135),\n",
       " ('get', 134),\n",
       " ('pop-up', 121),\n",
       " ('one', 120),\n",
       " ('time', 116),\n",
       " ('social', 113),\n",
       " ('great', 112),\n",
       " ('circles', 111),\n",
       " ('party', 107),\n",
       " ('today', 101),\n",
       " ('line', 100),\n",
       " ('like', 100),\n",
       " ('free', 100),\n",
       " ('via', 97),\n",
       " (\"'m\", 97),\n",
       " ('cool', 96),\n",
       " ('apps', 89),\n",
       " ('people', 87),\n",
       " ('maps', 87),\n",
       " ('day', 87),\n",
       " ('go', 83),\n",
       " ('good', 79),\n",
       " ('sxswi', 79),\n",
       " ('got', 77),\n",
       " ('love', 75),\n",
       " ('mobile', 75),\n",
       " ('network', 72),\n",
       " ('awesome', 71),\n",
       " ('opening', 70),\n",
       " ('temporary', 68),\n",
       " (\"'re\", 67),\n",
       " ('w/', 66),\n",
       " ('see', 66),\n",
       " ('check', 65),\n",
       " ('downtown', 64),\n",
       " ('need', 64),\n",
       " ('\\x89ûï', 59),\n",
       " ('thanks', 58),\n",
       " ('first', 58),\n",
       " ('best', 58),\n",
       " ('called', 57),\n",
       " ('going', 56),\n",
       " ('popup', 55),\n",
       " ('design', 54),\n",
       " ('major', 54),\n",
       " ('come', 53),\n",
       " ('open', 51),\n",
       " ('users', 51),\n",
       " ('next', 51),\n",
       " ('mayer', 50),\n",
       " ('around', 50),\n",
       " ('use', 49),\n",
       " ('ever', 49),\n",
       " ('even', 49),\n",
       " (\"'ve\", 48),\n",
       " ('think', 47),\n",
       " (\"'ll\", 47),\n",
       " ('heard', 46),\n",
       " ('want', 46),\n",
       " ('news', 45),\n",
       " ('win', 45),\n",
       " ('really', 45),\n",
       " ('us', 44),\n",
       " ('would', 44),\n",
       " ('know', 43),\n",
       " ('fun', 43),\n",
       " ('using', 42),\n",
       " ('coming', 41),\n",
       " ('tech', 41),\n",
       " ('nice', 40),\n",
       " ('big', 40),\n",
       " ('marissa', 40),\n",
       " ('technology', 40),\n",
       " ('could', 40),\n",
       " ('right', 39),\n",
       " ('4', 38),\n",
       " ('pop', 38),\n",
       " ('comes', 38),\n",
       " ('still', 38),\n",
       " ('game', 38),\n",
       " ('case', 38),\n",
       " ('video', 38),\n",
       " ('panel', 38),\n",
       " ('team', 38),\n",
       " ('set', 37),\n",
       " ('gt', 36),\n",
       " ('shop', 36),\n",
       " ('talk', 36),\n",
       " ('better', 36),\n",
       " ('possibly', 36),\n",
       " ('phone', 36),\n",
       " ('search', 35),\n",
       " ('smart', 35),\n",
       " ('work', 34),\n",
       " ('wow', 34),\n",
       " ('much', 34),\n",
       " ('wait', 33),\n",
       " ('year', 33),\n",
       " ('wins', 33),\n",
       " ('way', 33),\n",
       " ('thing', 33),\n",
       " ('buy', 32),\n",
       " ('ipads', 32),\n",
       " ('everyone', 32),\n",
       " ('music', 32),\n",
       " ('marketing', 31),\n",
       " ('away', 31),\n",
       " ('yes', 31),\n",
       " ('week', 31),\n",
       " ('make', 31),\n",
       " ('--', 31),\n",
       " ('also', 30),\n",
       " ('..', 30),\n",
       " ('looking', 30),\n",
       " ('back', 29),\n",
       " ('fast', 29),\n",
       " ('already', 29),\n",
       " ('may', 29),\n",
       " ('web', 29),\n",
       " ('rumor', 29),\n",
       " ('every', 29),\n",
       " ('well', 29),\n",
       " ('live', 28),\n",
       " ('session', 28),\n",
       " ('getting', 28),\n",
       " ('says', 27),\n",
       " ('booth', 27),\n",
       " ('look', 27),\n",
       " ('tonight', 27),\n",
       " ('begins', 27),\n",
       " ('last', 27),\n",
       " ('temp', 26),\n",
       " ('conferences', 26),\n",
       " ('looks', 26),\n",
       " ('amazing', 26),\n",
       " ('download', 26),\n",
       " ('hey', 26),\n",
       " ('made', 26),\n",
       " ('giving', 25),\n",
       " ('guy', 25),\n",
       " ('tomorrow', 25),\n",
       " ('excited', 25),\n",
       " ('1', 25),\n",
       " ('tapworthy', 25),\n",
       " ('product', 25),\n",
       " ('sxsw\\x89û\\x9d', 25),\n",
       " ('interactive', 25),\n",
       " ('ready', 25),\n",
       " ('keep', 25),\n",
       " ('winning', 24),\n",
       " ('3', 24),\n",
       " ('long', 24),\n",
       " ('show', 24),\n",
       " ('ca', 24),\n",
       " ('info', 23),\n",
       " ('u', 23),\n",
       " ('tweet', 23),\n",
       " ('far', 23),\n",
       " ('years', 23),\n",
       " ('action', 23),\n",
       " ('tv', 23),\n",
       " ('available', 23),\n",
       " ('white', 22),\n",
       " ('2011', 22),\n",
       " ('itunes', 22),\n",
       " ('oh', 22),\n",
       " ('many', 22),\n",
       " ('pretty', 22),\n",
       " ('take', 22),\n",
       " ('company', 22),\n",
       " ('bing', 22),\n",
       " ('makes', 22),\n",
       " ('traffic', 22),\n",
       " ('future', 22),\n",
       " ('lt', 21),\n",
       " ('digital', 21),\n",
       " ('market', 21),\n",
       " ('world', 21),\n",
       " ('attendees', 21),\n",
       " ('twitter', 21),\n",
       " ('release', 21)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create frequency distribution to see which words appear the most\n",
    "tweets_concat = []\n",
    "for tweet in processed_data:\n",
    "    tweets_concat += tweet\n",
    "    \n",
    "tweet_freqdist = FreqDist(tweets_concat)\n",
    "tweet_freqdist.most_common(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this is a frequency distribution across both of our sentiments (positive and negative), it is likely that the words presented above are the least important, as they are shared among both classses.  Knowing this, we will try to focus on words that appear frequently in one class but not the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import proper libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# vectorize train and test data\n",
    "tf_idf_data_train = vectorizer.fit_transform(train_data)\n",
    "tf_idf_data_test = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2654, 5199)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at shape of our vectorized data\n",
    "tf_idf_data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our vectorized data contains 2,654 tweets, with 5,199 unique words in the vocabulary.  The vast majority of these columns for any given tweet will be zero, since every article contains a small subset of the total vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Non-Zero Elements in Vectorized Tweets: 16.66164280331575\n",
      "Percentage of columns containing 0: 0.9967952216189044\n"
     ]
    }
   ],
   "source": [
    "# display number of non-zero columns in the vectors\n",
    "non_zero_cols = tf_idf_data_train.nnz / float(tf_idf_data_train.shape[0])\n",
    "print(f'Average Number of Non-Zero Elements in Vectorized Tweets: {non_zero_cols}')\n",
    "\n",
    "percent_sparse = 1 - (non_zero_cols / float(tf_idf_data_train.shape[1]))\n",
    "print(f'Percentage of columns containing 0: {percent_sparse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above the average tweet contains ~16 non-zero columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate initial models\n",
    "nb_classifier = MultinomialNB()\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit naive bayes model\n",
    "nb_classifier.fit(tf_idf_data_train, train_target)\n",
    "nb_train_preds = nb_classifier.predict(tf_idf_data_train)\n",
    "nb_test_preds = nb_classifier.predict(tf_idf_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit random forest classifier\n",
    "rf_classifier.fit(tf_idf_data_train, train_target)\n",
    "rf_train_preds = rf_classifier.predict(tf_idf_data_train)\n",
    "rf_test_preds = rf_classifier.predict(tf_idf_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "nb_train_score = accuracy_score(train_target, nb_train_preds)\n",
    "nb_test_score = accuracy_score(test_target, nb_test_preds)\n",
    "rf_train_score = accuracy_score(train_target, rf_train_preds)\n",
    "rf_test_score = accuracy_score(test_target, rf_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "Training Accuracy: 0.8497 \t\t Testing Accuracy: 0.8418\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest\n",
      "Training Accuracy: 1.0 \t\t Testing Accuracy: 0.8655\n"
     ]
    }
   ],
   "source": [
    "print(\"Multinomial Naive Bayes\")\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(nb_train_score, nb_test_score))\n",
    "print(\"\")\n",
    "print('-'*70)\n",
    "print(\"\")\n",
    "print('Random Forest')\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(rf_train_score, rf_test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# think about further lemmatizing, n-grams, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling\n",
    "This is a classification task, aimed at classifying tweets based on their sentiment.  As a result, we will iterate through a number of potential models / hyperparameters to arrive at the optimal model for our task.\n",
    "\n",
    "Following metrics will be generated to help evaluate models:\n",
    "* Accuracy: total number of correct predictions out of total observations\n",
    "* Recall: number of true positives out of actual total positives.\n",
    "* Precision: number of true positives out of predicted positives.\n",
    "* F1 Score: harmonic mean of precision and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
